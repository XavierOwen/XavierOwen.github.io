---
title: "Gaussian Process Regression in High-Dimensional and Structured Domains: Variational Inference and Active Learning on Manifolds"
collection: publications
category: manuscripts
permalink: /publication/2025-08-01-Thesis
excerpt: 'This thesis develops new methods for Gaussian process regression in high-dimensional and structured domains, focusing on reliable inference with limited data and efficient sample selection. It introduces Energetic Variational Inference for Gaussian Processes (EVI-GP), an energy-based approach for stable and interpretable inference, and Active Learning for Manifold Gaussian Processes (ALmGP), which combines manifold learning and active data acquisition to improve sample efficiency and robustness in complex modeling tasks.'
date: 2025-08-01
venue: 'IIT'
slidesurl: 'http://XavierOwen.github.io/files/Thesis-slides.pdf'
paperurl: 'http://XavierOwen.github.io/files/Thesis.pdf'
biburlbibtexurl: 'http://XavierOwen.github.io/files/Thesis-bib.bib'
citation: 'Yuanxing Cheng. (2025). "Gaussian Process Regression in High-Dimensional and Structured Domains: Variational Inference and Active Learning on Manifolds." Ph.D. Thesis, Illinois Institute of Technology.'
---

Gaussian process (GP) regression offers a useful framework for surrogate modeling, providing both predictive flexibility and rigorous uncertainty quantification. As computational models grow in complexity, two fundamental challenges arise: how to perform reliable inference with limited data, and how to select data points effectively
when evaluations are expensive. This thesis addresses both challenges through two complementary approaches.

First, we develop an inference framework called Energetic Variational Inference for Gaussian Processes (EVI-GP). Instead of relying on variational bounds or sampling-based methods, EVI-GP constructs an energy-based functional grounded in thermodynamic principles. Using a particle-based implicit solver, the method captures the posterior shape and mode while incorporating shrinkage priors for variable selection. This results in a stable, interpretable inference mechanism that is effective in high-dimensional or data-scarce settings.

Second, we propose an active learning framework called Active Learning for Manifold Gaussian Processes (ALmGP). This method uncovers a low-dimensional latent structure using an autoencoder trained together with the GP model, and places
the GP within this space. Data acquisition is guided by the Active Learning Cohn (ALC) criterion, which selects new samples to reduce global predictive uncertainty. This approach improves sample efficiency and enhances robustness in complex, nonlinear modeling tasks.