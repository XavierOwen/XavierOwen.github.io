---
title: "Simple scraper for çº¦ç¿°ç¦éŸ³è®²é“å½•"
collection: projects
category: scraper
excerpt: "a simple scraper to obtain passages of lectures on Gospel of Jone from [this website](https://www.newadvent.org/fathers/1701.htm)"
permalink: "/games/scraper-lectures-on-the-Gospel-of-John"
date: 2025-08-25
---

# åœ¨çº¿æŠ“å–æ·±æ–‡ç†å’Œåˆæœ¬å†…å®¹

[åŸæ–‡é“¾æ¥](https://www.newadvent.org/fathers/1701.htm)

[ä»£ç é“¾æ¥](https://github.com/XavierOwen/Practicing-simple-spider/blob/main/scraper-lectures-on-the-Gospel-of-John.py)

## æ­¥éª¤

1. çŒœæµ‹å‡ºæ‰€æœ‰æ–‡ç« çš„é“¾æ¥
2. ä¾æ¬¡æå–titleå’Œæ­£æ–‡
3. æ­£æ–‡ä¸­çš„ç‰¹æ®Šæ ¼å¼ä»htmlè½¬åˆ°md

<details markdown="1">
<summary>Show Python code</summary>

```python
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import time

BASE_URL = "https://www.newadvent.org/"

def html_to_markdown(paragraph, base_url):
    # æ›¿æ¢æ–œä½“
    for i_tag in paragraph.find_all('i'):
        i_tag.insert_before("*")
        i_tag.insert_after("*")
        i_tag.unwrap()
    # æ›¿æ¢ç²—ä½“
    for b_tag in paragraph.find_all('b'):
        b_tag.insert_before("**")
        b_tag.insert_after("**")
        b_tag.unwrap()
    # æ›¿æ¢è¶…é“¾æ¥ä¸ºå®Œæ•´ URL
    for a_tag in paragraph.find_all('a'):
        href = a_tag.get('href', '')
        if href.startswith("#"):
            a_tag.unwrap()  # ä¸¢å¼ƒé”šç‚¹é“¾æ¥
            continue
        full_url = urljoin(base_url, href)
        text = a_tag.get_text()
        a_tag.replace_with(f"[{text}]({full_url})")
    return paragraph.get_text(strip=False)

def fetch_all_to_one_md(start=1, end=124, output_file='fathers.md'):
    all_md_lines = []

    for i in range(start, end + 1):
        page_url = f"https://www.newadvent.org/fathers/1701{i:03d}.htm"
        print(f"ğŸ“¥ Fetching: {page_url}")
        try:
            response = requests.get(page_url)
            response.raise_for_status()
        except requests.RequestException as e:
            print(f"âŒ Failed to fetch {page_url}: {e}")
            continue

        soup = BeautifulSoup(response.text, 'html.parser')

        # æå– <h1> æ ‡é¢˜
        title_tag = soup.find('h1')
        title = title_tag.get_text(strip=True) if title_tag else f"Article {i}"
        all_md_lines.append(f"## {title}")

        # æå– <p> å¹¶è·³è¿‡ç¬¬ä¸€ä¸ª
        paragraphs = soup.find_all('p')
        for p in paragraphs[1:]:
            md_line = html_to_markdown(p, base_url=page_url)
            if md_line.strip():
                all_md_lines.append(md_line)

        # åˆ†éš”çº¿
        all_md_lines.append("\n---\n")
        time.sleep(5)

    # å†™å…¥ Markdown æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write('\n\n'.join(all_md_lines))

    print(f"\nâœ… All {end-start+1} articles saved to '{output_file}'.")

if __name__ == '__main__':
    fetch_all_to_one_md()
```
</details>
